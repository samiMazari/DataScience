# 1. Glossary: From Requirements to Collection

Welcome! This alphabetized glossary contains many of the terms you’ll find within this lesson. These terms are important for you to recognize when working in the industry, when participating in user groups, and when participating in other certificate programs.

| **Term**                          | **Definition**                                                                                                                                                     |
|-----------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Analytics team                    | A group of professionals, including data scientists and analysts, responsible for performing data analysis and modeling.                                            |
| Data collection                   | The process of gathering data from various sources, including demographic, clinical, coverage, and pharmaceutical information.                                      |
| Data integration                  | The merging of data from multiple sources to remove redundancy and prepare it for further analysis.                                                                 |
| Data Preparation                  | The process of organizing and formatting data to meet the requirements of the modeling technique.                                                                   |
| Data Requirements                 | The identification and definition of the necessary data elements, formats, and sources required for analysis.                                                      |
| Data Understanding               | A stage where data scientists discuss various ways to manage data effectively, including automating certain processes in the database.                              |
| DBAs (Database Administrators)    | The professionals who are responsible for managing and extracting data from databases.                                                                             |
| Decision tree classification      | A modeling technique that uses a tree-like structure to classify data based on specific conditions and variables.                                                   |
| Demographic information           | Information about patient characteristics, such as age, gender, and location.                                                                                       |
| Descriptive statistics            | Techniques used to analyze and summarize data, providing initial insights and identifying gaps in data.                                                             |
| Intermediate results              | Partial results obtained from predictive modeling can influence decisions on acquiring additional data.                                                             |
| Patient cohort                    | A group of patients with specific criteria selected for analysis in a study or model.                                                                               |
| Predictive modeling               | The building of models to predict future outcomes based on historical data.                                                                                         |
| Training set                      | A subset of data used to train or fit a machine learning model; consists of input data and corresponding known or labeled output values.                           |
| Unavailable data                  | Data elements are not currently accessible or integrated into the data sources.                                                                                     |
| Univariate                        | Modeling analysis focused on a single variable or feature at a time, considering its characteristics and relationship to other variables independently.            |
| Unstructured data                 | Data that does not have a predefined structure or format, typically text images, audio, or video, requires special techniques to extract meaning or insights.       |
| Visualization                     | The process of representing data visually to gain insights into its content and quality.                                                                            |


# 2. Glossary: From Understanding to Preparation

This alphabetized glossary contains many of the terms you’ll find within this lesson. These terms are important for you to recognize when working in the industry, when participating in user groups, and when participating in other certificate programs.

| **Term**                      | **Definition**                                                                                                                                                         |
|------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Automation                   | Using tools and techniques to streamline data collection and preparation processes.                                                                                      |
| Data Collection              | The phase of gathering and assembling data from various sources.                                                                                                         |
| Data Compilation             | The process of organizing and structuring data to create a comprehensive data set.                                                                                       |
| Data Formatting              | The process of standardizing the data to ensure uniformity and ease of analysis.                                                                                        |
| Data Manipulation            | The process of transforming data into a usable format.                                                                                                                   |
| Data Preparation             | The phase where data is cleaned, transformed, and formatted for further analysis, including feature engineering and text analysis.                                       |
| Data Preparation             | The stage where data is transformed and organized to facilitate effective analysis and modeling.                                                                         |
| Data Quality                 | Assessment of data integrity and completeness, addressing missing, invalid, or misleading values.                                                                         |
| Data Quality Assessment      | The evaluation of data integrity, accuracy, and completeness.                                                                                                             |
| Data Set                     | A collection of data used for analysis and modeling.                                                                                                                     |
| Data Understanding           | The stage in the data science methodology focused on exploring and analyzing the collected data to ensure that the data is representative of the problem to be solved.   |
| Descriptive Statistics       | Summary statistics that data scientists use to describe and understand the distribution of variables, such as mean, median, minimum, maximum, and standard deviation.   |
| Feature                      | A characteristic or attribute within the data that helps in solving the problem.                                                                                         |
| Feature Engineering          | The process of creating new features or variables based on domain knowledge to improve machine learning algorithms' performance.                                          |
| Feature Extraction           | Identifying and selecting relevant features or attributes from the data set.                                                                                             |
| Interactive Processes        | Iterative and continuous refinement of the methodology based on insights and feedback from data analysis.                                                                |
| Missing Values               | Values that are absent or unknown in the dataset, requiring careful handling during data preparation.                                                                    |
| Model Calibration            | Adjusting model parameters to improve accuracy and alignment with the initial design.                                                                                    |
| Pairwise Correlations        | An analysis to determine the relationships and correlations between different variables.                                                                                 |
| Text Analysis                | Steps to analyze and manipulate textual data, extracting meaningful information and patterns.                                                                            |
| Text Analysis Groupings      | Creating meaningful groupings and categories from textual data for analysis.                                                                                            |
| Visualization techniques     | Methods and tools that data scientists use to create visual representations or graphics that enhance the accessibility and understanding of data patterns, relationships, and insights. |

# 3. Glossary: From Modeling to Evaluation

This alphabetized glossary contains many of the terms you’ll find within this lesson. These terms are important for you to recognize when working in the industry, when participating in user groups, and when participating in other certificate programs.

| **Term**                                    | **Definition**                                                                                                                                                         |
|---------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Binary classification model                 | A model that classifies data into two categories, such as yes/no or stop/go outcomes.                                                                                   |
| Data compilation                            | The process of gathering and organizing data required for modeling.                                                                                                     |
| Data modeling                               | The stage in the data science methodology where data scientists develop models, either descriptive or predictive, to answer specific questions.                         |
| Descriptive model                           | A type of model that examines relationships between variables and makes inferences based on observed patterns.                                                          |
| Diagnostic measure based tuning             | The process of fine-tuning the model by adjusting parameters based on diagnostic measures and performance indicators.                                                   |
| Diagnostic measures                         | The evaluation of a model’s performance to ensure that the model functions as intended.                                                                                 |
| Discrimination criterion                    | A measure used to evaluate the performance of the model in classifying different outcomes.                                                                              |
| False-positive rate                         | The rate at which the model incorrectly identifies negative outcomes as positive.                                                                                       |
| Histogram                                   | A graphical representation of the distribution of a dataset, where the data is divided into intervals or bins, and the height of each bar represents the frequency or count of data points falling within that interval. |
| Maximum separation                          | The point where the ROC curve provides the best discrimination between true-positive and false-positive rates, indicating the most effective model.                     |
| Model evaluation                            | The process of assessing the quality and relevance of the model before deployment.                                                                                      |
| Optimal model                               | The model that provides the maximum separation between the ROC curve and the baseline, indicating higher accuracy and effectiveness.                                   |
| Receiver Operating Characteristic (ROC)     | Originally developed for military radar, the military used this statistical curve to assess the performance of binary classification models.                           |
| Relative misclassification cost             | This measurement is a parameter in model building used to tune the trade-off between true-positive and false-positive rates.                                            |
| ROC curve (Receiver Operating Characteristic curve) | A diagnostic tool used to determine the optimal classification model’s performance.                                                                                      |
| Separation                                  | Separation is the degree of discrimination achieved by the model in correctly classifying outcomes.                                                                     |
| Statistical significance testing            | Evaluation technique to verify that data is appropriately handled and interpreted within the model.                                                                    |
| True-positive rate                          | The rate at which the model correctly identifies positive outcomes.                                                                                                     |
